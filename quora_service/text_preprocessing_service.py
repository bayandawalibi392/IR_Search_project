
import re
import nltk

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ù† nltk
nltk.download('punkt')
nltk.download('stopwords')


class TextPreprocessingService:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.stemmer = PorterStemmer()

    def preprocess(self, text, return_as_string=False):
        # 1. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø­Ø±Ù Ø¥Ù„Ù‰ ØµØºÙŠØ±Ø©
        text = text.lower()

        # 2. Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„Ø±Ù…ÙˆØ²
        text = re.sub(r'[^\w\s]', '', text)

        # 3. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        text = re.sub(r'\d+', '', text)

        # 4. Tokenization
        tokens = word_tokenize(text)

        # 5. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        tokens = [word for word in tokens if word not in self.stop_words and len(word) > 1]

        # 6. Stemming
        tokens = [self.stemmer.stem(word) for word in tokens]

        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ùˆ Ø§Ù„Ù†Øµ
        return " ".join(tokens) if return_as_string else tokens


# âœ… Ù…Ø«Ø§Ù„ Ù„Ù„ØªØ¬Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    service = TextPreprocessingService()

    sample_text = "This is an example sentence, with numbers like 123 and punctuation!!!"
    
    print("ðŸš€ Tokens:", service.preprocess(sample_text))
    print("ðŸ§¼ Clean text:", service.preprocess(sample_text, return_as_string=True))
