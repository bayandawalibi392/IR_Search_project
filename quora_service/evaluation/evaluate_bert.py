# import os
# import joblib
# import sqlite3
# import numpy as np
# from tqdm import tqdm
# from sklearn.metrics import average_precision_score
# from sklearn.metrics.pairwise import cosine_similarity
# from text_preprocessing_service import TextPreprocessingService
# from transformers import AutoTokenizer, AutoModel
# import torch

# # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# SOURCE = "quora"  # Ø£Ùˆ "quora"
# TOP_N = 10
# MODELS_DIR = "models"
# INDEX_DIR = "indexes"
# DB_PATH = "ir_project.db"

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³
# inverted_index = joblib.load(os.path.join(INDEX_DIR, f"inverted_index_{SOURCE}.joblib"))

# # ØªØ­Ù…ÙŠÙ„ ØªÙ…Ø«ÙŠÙ„Ø§Øª BERT
# doc_ids = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_doc_ids.joblib"))
# doc_vectors = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_vectors.joblib"))
# doc_id_to_idx = {doc_id: idx for idx, doc_id in enumerate(doc_ids)}

# # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT
# tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
# model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = model.to(device).eval()

# # Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ…Ø«ÙŠÙ„
# def embed(text):
#     tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)
#     with torch.no_grad():
#         output = model(**tokens)
#     return output.last_hidden_state.mean(dim=1).cpu().numpy()

# # Ø±Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# conn = sqlite3.connect(DB_PATH)
# cursor = conn.cursor()

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ù€ qrels
# cursor.execute("SELECT query_id, query_text FROM queries WHERE source = ?", (SOURCE,))
# queries = cursor.fetchall()
# cursor.execute("SELECT query_id, doc_id FROM qrels WHERE source = ?", (SOURCE,))
# qrels_raw = cursor.fetchall()

# qrels = {}
# for qid, doc_id in qrels_raw:
#     qrels.setdefault(qid, set()).add(doc_id)

# # ØªÙ‚ÙŠÙŠÙ…
# preprocessor = TextPreprocessingService()
# precisions, recalls, average_precisions, reciprocal_ranks = [], [], [], []

# print(f"\nâš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ {len(queries)} Ø§Ø³ØªØ¹Ù„Ø§Ù…...\n")

# for qid, qtext in tqdm(queries):
#     if qid not in qrels:
#         continue

#     relevant_docs = qrels[qid]
#     tokens = preprocessor.preprocess(qtext, return_as_string=False)

#     candidate_doc_ids = set()
#     for token in tokens:
#         if token in inverted_index:
#             candidate_doc_ids.update(inverted_index[token])

#     candidate_indices = [doc_id_to_idx[doc] for doc in candidate_doc_ids if doc in doc_id_to_idx]
#     if not candidate_indices:
#         continue

#     query_vec = embed(" ".join(tokens))
#     candidate_vectors = doc_vectors[candidate_indices]
#     sims = cosine_similarity(query_vec, candidate_vectors)[0]

#     ranked = sorted(zip(candidate_indices, sims), key=lambda x: x[1], reverse=True)
#     top_docs = [doc_ids[i] for i, _ in ranked[:TOP_N]]

#     # Precision@10
#     hits = [1 if doc in relevant_docs else 0 for doc in top_docs]
#     precisions.append(sum(hits) / TOP_N)
#     recalls.append(sum(hits) / len(relevant_docs))

#     # MAP
#     y_true = [1 if doc_ids[i] in relevant_docs else 0 for i in candidate_indices]
#     y_scores = sims
#     try:
#         ap = average_precision_score(y_true, y_scores)
#     except:
#         ap = 0.0
#     average_precisions.append(ap)

#     # MRR
#     for rank, doc in enumerate(top_docs, 1):
#         if doc in relevant_docs:
#             reciprocal_ranks.append(1 / rank)
#             break
#     else:
#         reciprocal_ranks.append(0.0)

# # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# print("\nğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT:")
# print(f"Precision@10: {np.mean(precisions):.4f}")
# print(f"Recall:        {np.mean(recalls):.4f}")
# print(f"MAP:           {np.mean(average_precisions):.4f}")
# print(f"MRR:           {np.mean(reciprocal_ranks):.4f}")

# conn.close()


import os
import joblib
import sqlite3
import numpy as np
import pandas as pd
import time
from tqdm import tqdm
from sklearn.metrics import average_precision_score
from sklearn.metrics.pairwise import cosine_similarity
from text_preprocessing_service import TextPreprocessingService
from transformers import AutoTokenizer, AutoModel
import torch
import json

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
SOURCE = "quora"
TOP_N = 10
MODELS_DIR = "models"
INDEX_DIR = "indexes"
DB_PATH = "ir_project.db"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³
inverted_index = joblib.load(os.path.join(INDEX_DIR, f"inverted_index_{SOURCE}.joblib"))

# ØªØ­Ù…ÙŠÙ„ ØªÙ…Ø«ÙŠÙ„Ø§Øª BERT
doc_ids = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_doc_ids.joblib"))
doc_vectors = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_vectors.joblib"))
doc_id_to_idx = {doc_id: idx for idx, doc_id in enumerate(doc_ids)}

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device).eval()

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ…Ø«ÙŠÙ„
def embed(text):
    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)
    with torch.no_grad():
        output = model(**tokens)
    return output.last_hidden_state.mean(dim=1).cpu().numpy()

# Ø±Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ù€ qrels
cursor.execute("SELECT query_id, query_text FROM queries WHERE source = ?", (SOURCE,))
queries = cursor.fetchall()
cursor.execute("SELECT query_id, doc_id FROM qrels WHERE source = ?", (SOURCE,))
qrels_raw = cursor.fetchall()

qrels = {}
for qid, doc_id in qrels_raw:
    qrels.setdefault(qid, set()).add(doc_id)

# ØªÙ‚ÙŠÙŠÙ…
preprocessor = TextPreprocessingService()
precisions, recalls, average_precisions, reciprocal_ranks = [], [], [], []

print(f"\nâš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ {len(queries)} Ø§Ø³ØªØ¹Ù„Ø§Ù…...\n")
start_time = time.perf_counter()

for qid, qtext in tqdm(queries):
    if qid not in qrels:
        continue

    relevant_docs = qrels[qid]
    tokens = preprocessor.preprocess(qtext, return_as_string=False)

    candidate_doc_ids = set()
    for token in tokens:
        if token in inverted_index:
            candidate_doc_ids.update(inverted_index[token])

    candidate_indices = [doc_id_to_idx[doc] for doc in candidate_doc_ids if doc in doc_id_to_idx]
    if not candidate_indices:
        continue

    query_vec = embed(" ".join(tokens))
    candidate_vectors = doc_vectors[candidate_indices]
    sims = cosine_similarity(query_vec, candidate_vectors)[0]

    ranked = sorted(zip(candidate_indices, sims), key=lambda x: x[1], reverse=True)
    top_docs = [doc_ids[i] for i, _ in ranked[:TOP_N]]

    # Precision@10
    hits = [1 if doc in relevant_docs else 0 for doc in top_docs]
    precisions.append(sum(hits) / TOP_N)
    recalls.append(sum(hits) / len(relevant_docs))

    # MAP
    y_true = [1 if doc_ids[i] in relevant_docs else 0 for i in candidate_indices]
    y_scores = sims
    try:
        ap = average_precision_score(y_true, y_scores)
    except:
        ap = 0.0
    average_precisions.append(ap)

    # MRR
    for rank, doc in enumerate(top_docs, 1):
        if doc in relevant_docs:
            reciprocal_ranks.append(1 / rank)
            break
    else:
        reciprocal_ranks.append(0.0)

end_time = time.perf_counter()
elapsed = round(end_time - start_time, 2)

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
results = {
    "Precision@10": round(np.mean(precisions), 4),
    "Recall": round(np.mean(recalls), 4),
    "MAP": round(np.mean(average_precisions), 4),
    "MRR": round(np.mean(reciprocal_ranks), 4),
    "Execution Time (seconds)": elapsed,
    "Queries Evaluated": len(precisions)
}

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DataFrame
results_df = pd.DataFrame([results])
print("\nğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT:")
print(results_df)

# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ JSON
with open("bert_evaluation_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, indent=4, ensure_ascii=False)

# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ CSV
results_df.to_csv("bert_evaluation_results.csv", index=False)

# Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„
conn.close()
