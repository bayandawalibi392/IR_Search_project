# import os
# import sqlite3
# import joblib
# import numpy as np
# from sklearn.metrics.pairwise import cosine_similarity
# from transformers import AutoTokenizer, AutoModel
# import torch
# from text_preprocessing_service import TextPreprocessingService

# # --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
# MODELS_DIR = "models"
# SOURCE = "quora"  # Ø£Ùˆ "quora"
# TOP_N = 10

# # ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ BERT Ù†ÙØ³Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø³Ø§Ø¨Ù‚Ù‹Ø§
# tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
# model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = model.to(device)
# model.eval()

# def embed_text(text):
#     """ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT Ù…Ø¹ mean pooling"""
#     encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)
#     with torch.no_grad():
#         model_output = model(**encoded_input)
#     embeddings = model_output.last_hidden_state.mean(dim=1).cpu().numpy()
#     return embeddings

# # Ø±Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# conn = sqlite3.connect("ir_project.db")
# cursor = conn.cursor()

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
# cursor.execute("SELECT query_id, query_text FROM queries WHERE source = ?", (SOURCE,))
# all_queries = cursor.fetchall()

# print(f"\nðŸ”Ž Ø§Ø®ØªØ± Ø§Ø³ØªØ¹Ù„Ø§Ù…Ù‹Ø§ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© {SOURCE.upper()}:")
# for i, (qid, qtext) in enumerate(all_queries[:10]):
#     print(f"{i+1}. {qtext}")

# index = int(input("\nðŸ“Œ Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… (1-10): ")) - 1
# query_id, query_text = all_queries[index]

# print(f"\nðŸ§  ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {query_text} (ID: {query_id})")

# # ØªØ­Ù…ÙŠÙ„ ØªÙ…Ø«ÙŠÙ„Ø§Øª BERT Ù„Ù„ÙˆØ«Ø§Ø¦Ù‚
# doc_ids = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_doc_ids.joblib"))
# doc_vectors = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_vectors.joblib"))  # numpy array

# # ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ©
# preprocessor = TextPreprocessingService()
# cleaned_query = preprocessor.preprocess(query_text, return_as_string=True)

# # ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø§Ù„Ù€ BERT
# query_vec = embed_text(cleaned_query)  # Ø´ÙƒÙ„ (1, embedding_dim)

# # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
# sims = cosine_similarity(query_vec, doc_vectors)[0]
# top_indices = np.argsort(sims)[::-1][:TOP_N]

# print(f"\nðŸ“„ Ø£Ø¹Ù„Ù‰ {TOP_N} Ù†ØªØ§Ø¦Ø¬ Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ùƒ:\n")

# for rank, idx in enumerate(top_indices, 1):
#     doc_id = doc_ids[idx]
#     similarity = sims[idx]

#     # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
#     cursor.execute("SELECT content FROM documents WHERE doc_id = ?", (doc_id,))
#     result = cursor.fetchone()
#     content = result[0] if result else "(Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ)"

#     print(f"{rank}. doc_id: {doc_id}")
#     print(f"   similarity: {similarity:.4f}")
#     print(f"   content: {content[:300]}...")  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 300 Ø­Ø±Ù ÙÙ‚Ø·
#     print("-" * 80)

# conn.close()
from flask import Flask, request, jsonify
import os
import sqlite3
import joblib
import numpy as np
import requests
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModel
import torch
import time

# Ø¥Ø¹Ø¯Ø§Ø¯ Flask
app = Flask(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
MODELS_DIR = "models"
SOURCE = "quora"
TOP_N = 10
DB_PATH = "ir_project.db"
PREPROCESS_API_URL = "http://127.0.0.1:5060/preprocess"  # Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ©

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT
print("ðŸ”„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT...")
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
model.eval()

def embed_text(text):
    """ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT Ù…Ø¹ mean pooling"""
    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)
    with torch.no_grad():
        model_output = model(**encoded_input)
    embeddings = model_output.last_hidden_state.mean(dim=1).cpu().numpy()
    return embeddings

# ØªØ­Ù…ÙŠÙ„ ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
print("ðŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚...")
doc_ids = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_doc_ids.joblib"))
doc_vectors = joblib.load(os.path.join(MODELS_DIR, f"bert_{SOURCE}_vectors.joblib"))

# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
cursor = conn.cursor()

@app.route('/search-bert', methods=['POST'])
def search_bert():
    data = request.get_json()
    query_text = data.get("query", "").strip()

    if not query_text:
        return jsonify({"error": "âš ï¸ ÙŠØ¬Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¶Ù…Ù† Ø§Ù„Ø­Ù‚Ù„ 'query'"}), 400

    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¥Ù„Ù‰ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ©
    try:
        response = requests.post(PREPROCESS_API_URL, json={
            "text": query_text,
            "return_as_string": True
        })
        if response.status_code != 200:
            return jsonify({"error": "âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ©"}), 500

        cleaned_query = response.json().get("clean_text", "")
    except Exception as e:
        return jsonify({"error": f"âš ï¸ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ©: {str(e)}"}), 500

    # ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT
    start_time = time.time()
    query_vec = embed_text(cleaned_query)
    sims = cosine_similarity(query_vec, doc_vectors)[0]
    top_indices = np.argsort(sims)[::-1][:TOP_N]
    end_time = time.time()

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results = []
    for rank, idx in enumerate(top_indices, 1):
        doc_id = doc_ids[idx]
        similarity = sims[idx]

        cursor.execute("SELECT content FROM documents WHERE doc_id = ?", (doc_id,))
        row = cursor.fetchone()
        content = row[0] if row else "(Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ)"

        results.append({
            "rank": rank,
            "doc_id": doc_id,
            "score": round(float(similarity), 4),
            "content": content[:300] + ("..." if len(content) > 300 else "")
        })

    return jsonify({
        "query": query_text,
        "cleaned_query": cleaned_query,
        "results": results,
        "execution_time": round(end_time - start_time, 4)
    })

if __name__ == '__main__':
    app.run(debug=True, port=5011)
