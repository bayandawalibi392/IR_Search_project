# from flask import Flask, request, jsonify
# from flask_cors import CORS
# import sqlite3
# import joblib
# import numpy as np
# import time
# from sklearn.metrics.pairwise import cosine_similarity
# import sys
# import os
# import textwrap

# # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
# from TextPreprocessor import TextPreprocessor

# # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# DB_PATH = 'ir_project.db'
# MODEL_DIR = 'models'
# GROUP = 'webis'
# TOP_K = 10

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±
# print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª...")
# tfidf_vectorizer = joblib.load(f"{MODEL_DIR}/tfidf_vectorizer_{GROUP}.joblib")
# tfidf_matrix = joblib.load(f"{MODEL_DIR}/tfidf_vectors_{GROUP}.joblib")
# doc_ids = joblib.load(f"{MODEL_DIR}/doc_ids_{GROUP}.joblib")

# # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬
# pre = TextPreprocessor()
# conn = sqlite3.connect(DB_PATH, check_same_thread=False)
# cursor = conn.cursor()

# # Ø¥Ø¹Ø¯Ø§Ø¯ Flask
# app = Flask(__name__)

# @app.route('/search', methods=['POST'])
# def search():
#     data = request.get_json()
#     query = data.get('query', '').strip()

#     if not query:
#         return jsonify({"error": "Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº"}), 400

#     # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
#     content = pre.preprocess(query)
#     if not content:
#         return jsonify({"error": "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."}), 400

#     query_text = ' '.join(content)
#     query_vec = tfidf_vectorizer.transform([query_text])

#     # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
#     start_time = time.perf_counter()
#     scores = cosine_similarity(query_vec, tfidf_matrix)[0]
#     top_indices = np.argsort(scores)[-TOP_K:][::-1]
#     end_time = time.perf_counter()
#     elapsed_time = end_time - start_time

#     results = []
#     for rank, idx in enumerate(top_indices, 1):
#         doc_id = doc_ids[idx]
#         score = scores[idx]
#         cursor.execute("SELECT content FROM documents WHERE doc_id = ? AND source = ?", (doc_id, GROUP))
#         row = cursor.fetchone()
#         content = row[0] if row else "(Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ)"

#         results.append({
#             "rank": rank,
#             "doc_id": doc_id,
#             "score": round(score, 4),
#             "content": textwrap.shorten(content, width=300)
#         })

#     return jsonify({
#         "execution_time": round(elapsed_time, 4),
#         "results": results
#     })

# if __name__ == '__main__':
#     app.run(debug=True)
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# import sqlite3
# import joblib
# import numpy as np
# import time
# from sklearn.metrics.pairwise import cosine_similarity
# import sys
# import os
# import textwrap

# # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
# from TextPreprocessor import TextPreprocessor

# # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# DB_PATH = 'ir_project.db'
# MODEL_DIR = 'models'
# GROUP = 'webis'
# TOP_K = 10

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±
# print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª...")
# tfidf_vectorizer = joblib.load(f"{MODEL_DIR}/tfidf_vectorizer_{GROUP}.joblib")
# tfidf_matrix = joblib.load(f"{MODEL_DIR}/tfidf_vectors_{GROUP}.joblib")
# doc_ids = joblib.load(f"{MODEL_DIR}/doc_ids_{GROUP}.joblib")

# # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬
# pre = TextPreprocessor()
# conn = sqlite3.connect(DB_PATH, check_same_thread=False)
# cursor = conn.cursor()

# # Ø¥Ø¹Ø¯Ø§Ø¯ Flask Ù…Ø¹ Ø¯Ø¹Ù… CORS
# app = Flask(__name__)
# CORS(app)  # Ù‡Ø°Ù‡ Ø§Ù„Ø³Ø·Ø± ÙŠÙØ¹Ù‘Ù„ Ø¯Ø¹Ù… CORS Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ØµÙˆÙ„

# @app.route('/search', methods=['POST'])
# def search():
#     data = request.get_json()
#     query = data.get('query', '').strip()

#     if not query:
#         return jsonify({"error": "Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº"}), 400

#     # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
#     content = pre.preprocess(query)
#     if not content:
#         return jsonify({"error": "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."}), 400

#     query_text = ' '.join(content)
#     query_vec = tfidf_vectorizer.transform([query_text])

#     # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
#     start_time = time.perf_counter()
#     scores = cosine_similarity(query_vec, tfidf_matrix)[0]
#     top_indices = np.argsort(scores)[-TOP_K:][::-1]
#     end_time = time.perf_counter()
#     elapsed_time = end_time - start_time

#     results = []
#     for rank, idx in enumerate(top_indices, 1):
#         doc_id = doc_ids[idx]
#         score = scores[idx]
#         cursor.execute("SELECT content FROM documents WHERE doc_id = ? AND source = ?", (doc_id, GROUP))
#         row = cursor.fetchone()
#         content = row[0] if row else "(Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ)"

#         results.append({
#             "rank": rank,
#             "doc_id": doc_id,
#             "score": round(score, 4),
#             "content": textwrap.shorten(content, width=300)
#         })

#     return jsonify({
#         "execution_time": round(elapsed_time, 4),
#         "results": results
#     })

# if __name__ == '__main__':
#     app.run(debug=True)




# tfidf_api_befor_webis.py
from flask import Flask, request, jsonify
from flask_cors import CORS
import sqlite3
import joblib
import numpy as np
import time
import requests
from sklearn.metrics.pairwise import cosine_similarity
import textwrap

# Ø¥Ø¹Ø¯Ø§Ø¯ Flask
app = Flask(__name__)
CORS(app)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
DB_PATH = 'ir_project.db'
MODEL_DIR = 'models'
GROUP = 'webis'
TOP_K = 10
PREPROCESS_API_URL = "http://localhost:5050/preprocess"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª...")
tfidf_vectorizer = joblib.load(f"{MODEL_DIR}/tfidf_vectorizer_{GROUP}.joblib")
tfidf_matrix = joblib.load(f"{MODEL_DIR}/tfidf_vectors_{GROUP}.joblib")
doc_ids = joblib.load(f"{MODEL_DIR}/doc_ids_{GROUP}.joblib")

# Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
cursor = conn.cursor()

@app.route('/query/tfidf', methods=['POST'])
def search():
    data = request.get_json()
    query = data.get('query', '').strip()

    if not query:
        return jsonify({"error": "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº"}), 400

    # ğŸ”„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø¯Ù…Ø© TextPreprocessor
    try:
        response = requests.post(PREPROCESS_API_URL, json={
            "text": query,
            "use_stemming": True,
            "use_lemmatization": False
        })
        print("ğŸ” Response code:", response.status_code)
        print("ğŸ“„ Response text:", response.text)
        if response.status_code != 200:
            return jsonify({"error": "âš ï¸ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙØ´Ù„Øª"}), 500
        
        tokens = response.json().get("tokens", [])
    except Exception as e:
        return jsonify({"error": f"âš ï¸ ØªØ¹Ø°Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"}), 500

    if not tokens:
        return jsonify({"error": "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"}), 400

    query_text = ' '.join(tokens)
    query_vec = tfidf_vectorizer.transform([query_text])

    start_time = time.perf_counter()
    scores = cosine_similarity(query_vec, tfidf_matrix)[0]
    top_indices = np.argsort(scores)[-TOP_K:][::-1]
    elapsed_time = time.perf_counter() - start_time

    results = []
    for rank, idx in enumerate(top_indices, 1):
        doc_id = doc_ids[idx]
        score = scores[idx]

        cursor.execute("SELECT content FROM documents WHERE doc_id = ? AND source = ?", (doc_id, GROUP))
        row = cursor.fetchone()
        content = row[0] if row else "(Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ)"

        results.append({
            "rank": rank,
            "doc_id": doc_id,
            "score": round(score, 4),
            # "content": textwrap.shorten(content, width=300)
            "content": content

        })

    return jsonify({
        "execution_time": round(float(elapsed_time), 4),
        "results": results
    })

if __name__ == '__main__':
    app.run(debug=True, port=5000)
