# import sqlite3
# import joblib
# import numpy as np
# import time
# from TextPreprocessor import TextPreprocessor
# import textwrap

# # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# DB_PATH = 'ir_project.db'
# MODEL_DIR = 'models'
# INDEX_DIR = 'indexes'
# GROUP = 'webis'
# TOP_K = 10

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
# print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø¹ÙƒÙˆØ³ ÙˆÙ†Ù…ÙˆØ°Ø¬ BM25...")
# inverted_index = joblib.load(f"{INDEX_DIR}/inverted_index1_{GROUP}.joblib")
# bm25 = joblib.load(f"{MODEL_DIR}/bm25_model_{GROUP}.joblib")
# doc_ids = joblib.load(f"{MODEL_DIR}/doc_ids_bm25_{GROUP}.joblib")
# tokenized_documents = joblib.load(f"{MODEL_DIR}/bm25_tokenized_docs_{GROUP}.joblib")

# # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# conn = sqlite3.connect(DB_PATH)
# cursor = conn.cursor()

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
# cursor.execute("SELECT query_id, query_text FROM queries WHERE source = ?", (GROUP,))
# queries = cursor.fetchall()

# if not queries:
#     print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
#     exit()

# # Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù†Ù‡Ø§
# print("\nğŸ“‹ Ø§Ø®ØªØ± Ø§Ø³ØªØ¹Ù„Ø§Ù…Ù‹Ø§ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©:")
# for i, (qid, qtext) in enumerate(queries[:10]):
#     print(f"{i+1}. {qtext[:80]}...")

# choice = input("\nğŸ”¢ Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªÙ†ÙÙŠØ°Ù‡ (Ø£Ùˆ 'exit' Ù„Ù„Ø®Ø±ÙˆØ¬): ")
# if choice.lower() == 'exit':
#     exit()
# try:
#     index = int(choice) - 1
#     if index < 0 or index >= len(queries):
#         raise IndexError
#     query = queries[index][1]
# except (ValueError, IndexError):
#     print("âš ï¸ Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ§Ù„Ø­.")
#     exit()

# # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
# pre = TextPreprocessor()

# # ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
# start_time = time.perf_counter()

# query_tokens = pre.tokenize(pre.clean_text(query))
# if not query_tokens:
#     print("âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
#     exit()

# # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙ‚Ø· Ù…Ù† Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø¹ÙƒÙˆØ³
# candidate_indices = set()
# for token in query_tokens:
#     if token in inverted_index:
#         candidate_indices.update(inverted_index[token])

# if not candidate_indices:
#     print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ«Ø§Ø¦Ù‚ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙÙŠ Ø§Ù„ÙÙ‡Ø±Ø³.")
#     exit()

# # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø§Øª BM25 ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
# scores = bm25.get_scores(query_tokens)
# candidate_indices = sorted(candidate_indices)

# # ØªØµÙÙŠØ© Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ù„ØªØ´Ù…Ù„ ÙÙ‚Ø· Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
# candidate_scores = [(idx, scores[idx]) for idx in candidate_indices]
# top_indices_with_scores = sorted(candidate_scores, key=lambda x: x[1], reverse=True)[:TOP_K]

# end_time = time.perf_counter()
# elapsed_time = end_time - start_time

# print(f"\nğŸ•’ Ø²Ù…Ù† Ø§Ù„ØªÙ†ÙÙŠØ°: {elapsed_time:.4f} Ø«Ø§Ù†ÙŠØ©")
# print(f"\nğŸ“„ Ø£Ø¹Ù„Ù‰ {TOP_K} Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BM25 + Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø¹ÙƒÙˆØ³:")

# for rank, (idx, score) in enumerate(top_indices_with_scores, 1):
#     doc_id = doc_ids[idx]

#     cursor.execute("SELECT content FROM documents WHERE doc_id = ? AND source = ?", (doc_id, GROUP))
#     row = cursor.fetchone()
#     content = row[0] if row else "(Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ)"

#     print(f"#{rank} | ğŸ”‘ ID: {doc_id} | ğŸ”¢ Score: {score:.4f}")
#     print(textwrap.shorten(content, width=300))
#     print()
# bm25_inv_api.py


from flask import Flask, request, jsonify
from flask_cors import CORS
import sqlite3, joblib, numpy as np, time, textwrap, requests

app = Flask(__name__)
CORS(app)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
DB_PATH = 'ir_project.db'
MODEL_DIR = 'models'
GROUP = 'webis'
TOP_K = 10
PREPROCESS_API_URL = "http://localhost:5050/preprocess"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
bm25 = joblib.load(f"{MODEL_DIR}/bm25_model_{GROUP}.joblib")
doc_ids = joblib.load(f"{MODEL_DIR}/doc_ids_bm25_{GROUP}.joblib")  # Ù‚Ø§Ø¦Ù…Ø© doc_ids

# Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
cursor = conn.cursor()

@app.route('/query/bm25-all', methods=['POST'])
def search_bm25_all():
    data = request.get_json()
    query = data.get('query', '').strip()
    if not query:
        return jsonify({"error": "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº"}), 400

    try:
        response = requests.post(PREPROCESS_API_URL, json={
            "text": query,
            "use_stemming": True,
            "use_lemmatization": False
        })
        tokens = response.json().get("tokens", [])
    except Exception as e:
        return jsonify({"error": f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"}), 500

    if not tokens:
        return jsonify({"error": "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"}), 400

    start = time.perf_counter()
    
    scores = bm25.get_scores(tokens)
    scores = scores.astype(float)  # Ù„ØªÙØ§Ø¯ÙŠ float32 ÙÙŠ JSON

    top_indices = np.argsort(scores)[-TOP_K:][::-1]
    top_doc_ids = [doc_ids[i] for i in top_indices]

    placeholders = ','.join(['?'] * len(top_doc_ids))
    cursor.execute(f"""
        SELECT doc_id, content FROM documents 
        WHERE doc_id IN ({placeholders}) AND source = ?
    """, (*top_doc_ids, GROUP))
    rows = dict(cursor.fetchall())

    elapsed = time.perf_counter() - start

    results = []
    for rank, idx in enumerate(top_indices, 1):
        doc_id = doc_ids[idx]
        score = round(float(scores[idx]), 4)
        content = textwrap.shorten(rows.get(doc_id, "(Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ)"), width=300)

        results.append({
            "rank": rank,
            "doc_id": doc_id,
            "score": score,
            "content": content
        })

    return jsonify({
        "execution_time": round(float(elapsed), 4),
        "results": results
    })

if __name__ == '__main__':
    app.run(debug=True, port=5008)
