import os
import sqlite3
import joblib
from sentence_transformers import SentenceTransformer
from TextPreprocessor import TextPreprocessor  # Ù„Ø§ Ø²Ø§Ù„ Ù…Ù…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ø¥Ù† Ø£Ø­Ø¨Ø¨Øª Ù„ØªÙ†Ø¸ÙŠÙ Ø¨Ø³ÙŠØ·ØŒ Ù„ÙƒÙ†Ù‡ Ù„ÙŠØ³ Ø¶Ø±ÙˆØ±ÙŠÙ‹Ø§

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
DB_PATH = 'ir_project.db'
OUTPUT_DIR = 'models'
GROUPS = ['webis']
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

# Ù†Ù…ÙˆØ°Ø¬ BERT
bert_model = SentenceTransformer('all-MiniLM-L6-v2')  # Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø¢Ø®Ø± Ù…Ù† huggingface

def build_bert_for_group(group_name):
    cursor.execute("SELECT doc_id, content FROM preprocessed_documents WHERE source = ?", (group_name,))
    rows = cursor.fetchall()

    doc_ids = []
    texts = []

    for doc_id, content_str in rows:
        if content_str:
            doc_ids.append(doc_id)
            texts.append(content_str.strip())

    print(f"âœ… Loaded {len(texts)} documents from group '{group_name}'")

    # ØªÙ…Ø«ÙŠÙ„ BERT
    embeddings = bert_model.encode(texts, batch_size=64, show_progress_bar=True)

    # Ø§Ù„ØªØ®Ø²ÙŠÙ†
    joblib.dump(embeddings, f"{OUTPUT_DIR}/bert_vectors_{group_name}.joblib")
    joblib.dump(doc_ids, f"{OUTPUT_DIR}/doc_ids_bert_{group_name}.joblib")
    print(f"ğŸ’¾ Saved BERT embeddings for group '{group_name}'")

# ØªÙ†ÙÙŠØ°
for group in GROUPS:
    build_bert_for_group(group)

print("âœ… BERT vectorization completed for all documents per group.")
