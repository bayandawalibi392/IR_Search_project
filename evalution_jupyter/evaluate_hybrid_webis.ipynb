{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f685a0f",
   "metadata": {},
   "source": [
    "import sqlite3\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from TextPreprocessor import TextPreprocessor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3862f",
   "metadata": {},
   "source": [
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
    "DB_PATH = 'ir_project.db'\n",
    "MODEL_DIR = 'models'\n",
    "INDEX_DIR = 'indexes'\n",
    "GROUP = 'webis'  # ÙÙ‚Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø­Ø¯Ø©\n",
    "TOP_K = 10\n",
    "ALPHA = 0.7  # Ù†Ø³Ø¨Ø© Ø¯Ù…Ø¬ TF-IDF Ùˆ BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c27d3",
   "metadata": {},
   "source": [
    "print(f\"ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©: {GROUP}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fd759",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
    "tfidf_vectorizer = joblib.load(f\"{MODEL_DIR}/tfidf_vectorizer_{GROUP}.joblib\")\n",
    "tfidf_matrix = joblib.load(f\"{MODEL_DIR}/tfidf_vectors_{GROUP}.joblib\")\n",
    "tfidf_doc_ids = joblib.load(f\"{MODEL_DIR}/doc_ids_{GROUP}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b154d",
   "metadata": {},
   "source": [
    "bert_vectors = joblib.load(f\"{MODEL_DIR}/bert_vectors_{GROUP}.joblib\")\n",
    "bert_doc_ids = joblib.load(f\"{MODEL_DIR}/doc_ids_bert_{GROUP}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95abf5",
   "metadata": {},
   "source": [
    "# Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ bert_vectors Ù„ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ ØªØ±ØªÙŠØ¨ tfidf_doc_ids\n",
    "bert_id_to_vec = dict(zip(bert_doc_ids, bert_vectors))\n",
    "bert_vectors_aligned = np.array([bert_id_to_vec[doc_id] for doc_id in tfidf_doc_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17676c24",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹ÙƒØ³ÙŠ\n",
    "inverted_index = joblib.load(f\"{INDEX_DIR}/inverted_index1_{GROUP}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edb0f9",
   "metadata": {},
   "source": [
    "# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52196275",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª\n",
    "cursor.execute(\"SELECT query_id, query_text FROM queries WHERE source = ?\", (GROUP,))\n",
    "queries = cursor.fetchall()\n",
    "query_dict = {q_id: text for q_id, text in queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10fa53",
   "metadata": {},
   "source": [
    "cursor.execute(\"SELECT query_id, doc_id FROM qrels WHERE source = ?\", (GROUP,))\n",
    "qrel_rows = cursor.fetchall()\n",
    "qrels = {}\n",
    "for q_id, doc_id in qrel_rows:\n",
    "    qrels.setdefault(q_id, set()).add(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d1994",
   "metadata": {},
   "source": [
    "# Ø§Ù„ØªØ­Ø¶ÙŠØ±\n",
    "pre = TextPreprocessor()\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455494d",
   "metadata": {},
   "source": [
    "# Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
    "map_scores, mrr_scores, recall_scores, precision_scores = [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4779f",
   "metadata": {},
   "source": [
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49608c",
   "metadata": {},
   "source": [
    "for query_id, query_text in query_dict.items():\n",
    "    tokens = pre.preprocess(query_text, use_stemming=True, use_lemmatization=False)\n",
    "    if not tokens:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed94ef",
   "metadata": {},
   "source": [
    "    query_str = pre.clean_text(' '.join(tokens))\n",
    "    query_vec_tfidf = tfidf_vectorizer.transform([query_str])\n",
    "    query_vec_bert = bert_model.encode([' '.join(tokens)]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ac504",
   "metadata": {},
   "source": [
    "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ù…Ù† Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹ÙƒØ³ÙŠ\n",
    "    candidate_indices = set()\n",
    "    for token in tokens:\n",
    "        if token in inverted_index:\n",
    "            candidate_indices.update(inverted_index[token])\n",
    "    if not candidate_indices:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2fb13",
   "metadata": {},
   "source": [
    "    candidate_indices = sorted(candidate_indices)\n",
    "    candidate_tfidf = tfidf_matrix[candidate_indices]\n",
    "    candidate_bert = bert_vectors_aligned[candidate_indices]\n",
    "    candidate_doc_ids = [tfidf_doc_ids[i] for i in candidate_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44ec68",
   "metadata": {},
   "source": [
    "    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙˆØ¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "    sim_tfidf = cosine_similarity(query_vec_tfidf, candidate_tfidf)[0]\n",
    "    sim_bert = cosine_similarity(query_vec_bert, candidate_bert)[0]\n",
    "    scores = ALPHA * sim_tfidf + (1 - ALPHA) * sim_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcca489",
   "metadata": {},
   "source": [
    "    top_indices = np.argsort(scores)[-TOP_K:][::-1]\n",
    "    retrieved = [candidate_doc_ids[i] for i in top_indices]\n",
    "    y_scores = scores[top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b48d79",
   "metadata": {},
   "source": [
    "    relevant_docs = qrels.get(query_id, set())\n",
    "    y_true = [1 if doc_id in relevant_docs else 0 for doc_id in retrieved]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086cd8c8",
   "metadata": {},
   "source": [
    "    # MAP\n",
    "    if any(y_true):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            map_scores.append(average_precision_score(y_true, y_scores))\n",
    "    else:\n",
    "        map_scores.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b20fb",
   "metadata": {},
   "source": [
    "    # MRR\n",
    "    for rank, rel in enumerate(y_true, 1):\n",
    "        if rel:\n",
    "            mrr_scores.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        mrr_scores.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bff1e9",
   "metadata": {},
   "source": [
    "    # Recall@K\n",
    "    recall = sum(y_true) / len(relevant_docs) if relevant_docs else 0\n",
    "    recall_scores.append(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6adbee",
   "metadata": {},
   "source": [
    "    # Precision@K\n",
    "    precision = sum(y_true) / len(y_true) if y_true else 0\n",
    "    precision_scores.append(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd5071e",
   "metadata": {},
   "source": [
    "end_time = time.perf_counter()\n",
    "elapsed = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fb6a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "# print(\"\\nâœ… Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù…ÙƒØªÙ…Ù„!\")\n",
    "# print(f\"ğŸ“Š MAP: {np.mean(map_scores):.4f}\")\n",
    "# print(f\"ğŸ“Š MRR: {np.mean(mrr_scores):.4f}\")\n",
    "# print(f\"ğŸ“Š Recall@{TOP_K}: {np.mean(recall_scores):.4f}\")\n",
    "# print(f\"ğŸ“Š Precision@{TOP_K}: {np.mean(precision_scores):.4f}\")\n",
    "# print(f\"ğŸ•’ Ø²Ù…Ù† Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒÙ„ÙŠ: {elapsed:.2f} Ø«Ø§Ù†ÙŠØ©\")\n",
    "import sqlite3\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from TextPreprocessor import TextPreprocessor\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3717495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
    "DB_PATH = 'ir_project.db'\n",
    "MODEL_DIR = 'models'\n",
    "INDEX_DIR = 'indexes'\n",
    "GROUP = 'webis'\n",
    "TOP_K = 10\n",
    "ALPHA = 0.7  # Ø§Ù„Ù†Ø³Ø¨Ø© Ø¨ÙŠÙ† TF-IDF ÙˆBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aea7dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©: webis...\n"
     ]
    }
   ],
   "source": [
    "print(f\"ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©: {GROUP}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a9f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
    "tfidf_vectorizer = joblib.load(f\"{MODEL_DIR}/tfidf_vectorizer_{GROUP}.joblib\")\n",
    "tfidf_matrix = joblib.load(f\"{MODEL_DIR}/tfidf_vectors_{GROUP}.joblib\")\n",
    "tfidf_doc_ids = joblib.load(f\"{MODEL_DIR}/doc_ids_{GROUP}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf7f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors = joblib.load(f\"{MODEL_DIR}/bert_vectors_{GROUP}.joblib\")\n",
    "bert_doc_ids = joblib.load(f\"{MODEL_DIR}/doc_ids_bert_{GROUP}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0c9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ bert_vectors Ø¨Ø­Ø³Ø¨ ØªØ±ØªÙŠØ¨ tfidf_doc_ids\n",
    "bert_id_to_vec = dict(zip(bert_doc_ids, bert_vectors))\n",
    "bert_vectors_aligned = np.array([bert_id_to_vec[doc_id] for doc_id in tfidf_doc_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b5bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹ÙƒØ³ÙŠ\n",
    "inverted_index = joblib.load(f\"{INDEX_DIR}/inverted_index1_{GROUP}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e193e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db31be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª\n",
    "cursor.execute(\"SELECT query_id, query_text FROM queries WHERE source = ?\", (GROUP,))\n",
    "queries = cursor.fetchall()\n",
    "query_dict = {q_id: text for q_id, text in queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac191e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT query_id, doc_id FROM qrels WHERE source = ?\", (GROUP,))\n",
    "qrel_rows = cursor.fetchall()\n",
    "qrels = {}\n",
    "for q_id, doc_id in qrel_rows:\n",
    "    qrels.setdefault(q_id, set()).add(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a1625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ù„ØªØ­Ø¶ÙŠØ±\n",
    "pre = TextPreprocessor()\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02679bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
    "map_scores, mrr_scores, recall_scores, precision_scores = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7626d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cfd097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id, query_text in query_dict.items():\n",
    "    tokens = pre.preprocess(query_text, use_stemming=True, use_lemmatization=False)\n",
    "    if not tokens:\n",
    "        continue\n",
    "\n",
    "    query_str = pre.clean_text(' '.join(tokens))\n",
    "    query_vec_tfidf = tfidf_vectorizer.transform([query_str])\n",
    "    query_vec_bert = bert_model.encode([' '.join(tokens)]).reshape(1, -1)\n",
    "\n",
    "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ†\n",
    "    candidate_indices = set()\n",
    "    for token in tokens:\n",
    "        if token in inverted_index:\n",
    "            candidate_indices.update(inverted_index[token])\n",
    "    if not candidate_indices:\n",
    "        continue\n",
    "\n",
    "    candidate_indices = sorted(candidate_indices)\n",
    "    candidate_tfidf = tfidf_matrix[candidate_indices]\n",
    "    candidate_bert = bert_vectors_aligned[candidate_indices]\n",
    "    candidate_doc_ids = [tfidf_doc_ids[i] for i in candidate_indices]\n",
    "\n",
    "    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡\n",
    "    sim_tfidf = cosine_similarity(query_vec_tfidf, candidate_tfidf)[0]\n",
    "    sim_bert = cosine_similarity(query_vec_bert, candidate_bert)[0]\n",
    "    scores = ALPHA * sim_tfidf + (1 - ALPHA) * sim_bert\n",
    "\n",
    "    top_indices = np.argsort(scores)[-TOP_K:][::-1]\n",
    "    retrieved = [candidate_doc_ids[i] for i in top_indices]\n",
    "    y_scores = scores[top_indices]\n",
    "\n",
    "    relevant_docs = qrels.get(query_id, set())\n",
    "    y_true = [1 if doc_id in relevant_docs else 0 for doc_id in retrieved]\n",
    "\n",
    "    # MAP\n",
    "    if any(y_true):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            map_scores.append(average_precision_score(y_true, y_scores))\n",
    "    else:\n",
    "        map_scores.append(0)\n",
    "\n",
    "    # MRR\n",
    "    for rank, rel in enumerate(y_true, 1):\n",
    "        if rel:\n",
    "            mrr_scores.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        mrr_scores.append(0)\n",
    "\n",
    "    # Recall@K\n",
    "    recall = sum(y_true) / len(relevant_docs) if relevant_docs else 0\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Precision@K\n",
    "    precision = sum(y_true) / len(y_true) if y_true else 0\n",
    "    precision_scores.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e691fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = time.perf_counter() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "346dbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "results = {\n",
    "    \"MAP\": round(np.mean(map_scores), 4),\n",
    "    \"MRR\": round(np.mean(mrr_scores), 4),\n",
    "    f\"Recall@{TOP_K}\": round(np.mean(recall_scores), 4),\n",
    "    f\"Precision@{TOP_K}\": round(np.mean(precision_scores), 4),\n",
    "    \"Execution Time (s)\": round(elapsed, 2),\n",
    "    \"Queries Evaluated\": len(map_scores)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb8c75cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù…ÙƒØªÙ…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Hybrid (TF-IDF + BERT)!\n",
      "{'Execution Time (s)': 57.71,\n",
      " 'MAP': np.float64(0.4271),\n",
      " 'MRR': np.float64(0.5106),\n",
      " 'Precision@10': np.float64(0.2571),\n",
      " 'Queries Evaluated': 49,\n",
      " 'Recall@10': np.float64(0.0572)}\n"
     ]
    }
   ],
   "source": [
    "# Ø·Ø¨Ø§Ø¹Ø© ÙˆØ¬Ø¯ÙˆÙ„\n",
    "print(\"\\nâœ… Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù…ÙƒØªÙ…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Hybrid (TF-IDF + BERT)!\")\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "997ba65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "      <th>Queries Evaluated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4271</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>57.71</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAP     MRR  Recall@10  Precision@10  Execution Time (s)  \\\n",
       "0  0.4271  0.5106     0.0572        0.2571               57.71   \n",
       "\n",
       "   Queries Evaluated  \n",
       "0                 49  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame([results])\n",
    "display(df_results)  # Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø®Ù„ Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cdad83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "with open(\"hybrid_evaluation_results_webis.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
