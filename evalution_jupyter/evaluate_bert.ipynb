{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffd3621",
   "metadata": {},
   "source": [
    "import os\n",
    "import joblib\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from text_preprocessing_service import TextPreprocessingService\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60f4b7",
   "metadata": {},
   "source": [
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
    "SOURCE = \"quora\"  # Ø£Ùˆ \"quora\"\n",
    "TOP_N = 10\n",
    "MODELS_DIR = \"models\"\n",
    "INDEX_DIR = \"indexes\"\n",
    "DB_PATH = \"ir_project.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2ff03",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³\n",
    "inverted_index = joblib.load(os.path.join(INDEX_DIR, f\"inverted_index_{SOURCE}.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766839e4",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ ØªÙ…Ø«ÙŠÙ„Ø§Øª BERT\n",
    "doc_ids = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_doc_ids.joblib\"))\n",
    "doc_vectors = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_vectors.joblib\"))\n",
    "doc_id_to_idx = {doc_id: idx for idx, doc_id in enumerate(doc_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87fbd20",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fff29c",
   "metadata": {},
   "source": [
    "# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ…Ø«ÙŠÙ„\n",
    "def embed(text):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c1bf5",
   "metadata": {},
   "source": [
    "# Ø±Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73445214",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ù€ qrels\n",
    "cursor.execute(\"SELECT query_id, query_text FROM queries WHERE source = ?\", (SOURCE,))\n",
    "queries = cursor.fetchall()\n",
    "cursor.execute(\"SELECT query_id, doc_id FROM qrels WHERE source = ?\", (SOURCE,))\n",
    "qrels_raw = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd41a3b",
   "metadata": {},
   "source": [
    "qrels = {}\n",
    "for qid, doc_id in qrels_raw:\n",
    "    qrels.setdefault(qid, set()).add(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c78bd",
   "metadata": {},
   "source": [
    "# ØªÙ‚ÙŠÙŠÙ…\n",
    "preprocessor = TextPreprocessingService()\n",
    "precisions, recalls, average_precisions, reciprocal_ranks = [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ccc65",
   "metadata": {},
   "source": [
    "print(f\"\\nâš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ {len(queries)} Ø§Ø³ØªØ¹Ù„Ø§Ù…...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c981e2",
   "metadata": {},
   "source": [
    "for qid, qtext in tqdm(queries):\n",
    "    if qid not in qrels:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4f5f3",
   "metadata": {},
   "source": [
    "    relevant_docs = qrels[qid]\n",
    "    tokens = preprocessor.preprocess(qtext, return_as_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef06b82",
   "metadata": {},
   "source": [
    "    candidate_doc_ids = set()\n",
    "    for token in tokens:\n",
    "        if token in inverted_index:\n",
    "            candidate_doc_ids.update(inverted_index[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a69fd1",
   "metadata": {},
   "source": [
    "    candidate_indices = [doc_id_to_idx[doc] for doc in candidate_doc_ids if doc in doc_id_to_idx]\n",
    "    if not candidate_indices:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54aeeb4",
   "metadata": {},
   "source": [
    "    query_vec = embed(\" \".join(tokens))\n",
    "    candidate_vectors = doc_vectors[candidate_indices]\n",
    "    sims = cosine_similarity(query_vec, candidate_vectors)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795cb32",
   "metadata": {},
   "source": [
    "    ranked = sorted(zip(candidate_indices, sims), key=lambda x: x[1], reverse=True)\n",
    "    top_docs = [doc_ids[i] for i, _ in ranked[:TOP_N]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80ac75",
   "metadata": {},
   "source": [
    "    # Precision@10\n",
    "    hits = [1 if doc in relevant_docs else 0 for doc in top_docs]\n",
    "    precisions.append(sum(hits) / TOP_N)\n",
    "    recalls.append(sum(hits) / len(relevant_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f18485",
   "metadata": {},
   "source": [
    "    # MAP\n",
    "    y_true = [1 if doc_ids[i] in relevant_docs else 0 for i in candidate_indices]\n",
    "    y_scores = sims\n",
    "    try:\n",
    "        ap = average_precision_score(y_true, y_scores)\n",
    "    except:\n",
    "        ap = 0.0\n",
    "    average_precisions.append(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6192fc",
   "metadata": {},
   "source": [
    "    # MRR\n",
    "    for rank, doc in enumerate(top_docs, 1):\n",
    "        if doc in relevant_docs:\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        reciprocal_ranks.append(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c627d9",
   "metadata": {},
   "source": [
    "# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "print(\"\\nğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT:\")\n",
    "print(f\"Precision@10: {np.mean(precisions):.4f}\")\n",
    "print(f\"Recall:        {np.mean(recalls):.4f}\")\n",
    "print(f\"MAP:           {np.mean(average_precisions):.4f}\")\n",
    "print(f\"MRR:           {np.mean(reciprocal_ranks):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e9a51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e37d9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from text_preprocessing_service import TextPreprocessingService\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeec5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
    "SOURCE = \"quora\"\n",
    "TOP_N = 10\n",
    "MODELS_DIR = \"models\"\n",
    "INDEX_DIR = \"indexes\"\n",
    "DB_PATH = \"ir_project.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2e2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³\n",
    "inverted_index = joblib.load(os.path.join(INDEX_DIR, f\"inverted_index_{SOURCE}.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2244d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ ØªÙ…Ø«ÙŠÙ„Ø§Øª BERT\n",
    "doc_ids = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_doc_ids.joblib\"))\n",
    "doc_vectors = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_vectors.joblib\"))\n",
    "doc_id_to_idx = {doc_id: idx for idx, doc_id in enumerate(doc_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6aed21",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b9c488",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ…Ø«ÙŠÙ„\n",
    "def embed(text):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70301848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø±Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9a4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ù€ qrels\n",
    "cursor.execute(\"SELECT query_id, query_text FROM queries WHERE source = ?\", (SOURCE,))\n",
    "queries = cursor.fetchall()\n",
    "cursor.execute(\"SELECT query_id, doc_id FROM qrels WHERE source = ?\", (SOURCE,))\n",
    "qrels_raw = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3bfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = {}\n",
    "for qid, doc_id in qrels_raw:\n",
    "    qrels.setdefault(qid, set()).add(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "309d0fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªÙ‚ÙŠÙŠÙ…\n",
    "preprocessor = TextPreprocessingService()\n",
    "precisions, recalls, average_precisions, reciprocal_ranks = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "126e8d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ 5000 Ø§Ø³ØªØ¹Ù„Ø§Ù…...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nâš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ {len(queries)} Ø§Ø³ØªØ¹Ù„Ø§Ù…...\\n\")\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc8db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4732/5000 [13:00<00:17, 15.15it/s]C:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [13:31<00:00,  6.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for qid, qtext in tqdm(queries):\n",
    "    if qid not in qrels:\n",
    "        continue\n",
    "\n",
    "    relevant_docs = qrels[qid]\n",
    "    tokens = preprocessor.preprocess(qtext, return_as_string=False)\n",
    "\n",
    "    candidate_doc_ids = set()\n",
    "    for token in tokens:\n",
    "        if token in inverted_index:\n",
    "            candidate_doc_ids.update(inverted_index[token])\n",
    "\n",
    "    candidate_indices = [doc_id_to_idx[doc] for doc in candidate_doc_ids if doc in doc_id_to_idx]\n",
    "    if not candidate_indices:\n",
    "        continue\n",
    "\n",
    "    query_vec = embed(\" \".join(tokens))\n",
    "    candidate_vectors = doc_vectors[candidate_indices]\n",
    "    sims = cosine_similarity(query_vec, candidate_vectors)[0]\n",
    "\n",
    "    ranked = sorted(zip(candidate_indices, sims), key=lambda x: x[1], reverse=True)\n",
    "    top_docs = [doc_ids[i] for i, _ in ranked[:TOP_N]]\n",
    "\n",
    "    # Precision@10\n",
    "    hits = [1 if doc in relevant_docs else 0 for doc in top_docs]\n",
    "    precisions.append(sum(hits) / TOP_N)\n",
    "    recalls.append(sum(hits) / len(relevant_docs))\n",
    "\n",
    "    # MAP\n",
    "    y_true = [1 if doc_ids[i] in relevant_docs else 0 for i in candidate_indices]\n",
    "    y_scores = sims\n",
    "    try:\n",
    "        ap = average_precision_score(y_true, y_scores)\n",
    "    except:\n",
    "        ap = 0.0\n",
    "    average_precisions.append(ap)\n",
    "\n",
    "    # MRR\n",
    "    for rank, doc in enumerate(top_docs, 1):\n",
    "        if doc in relevant_docs:\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        reciprocal_ranks.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3385e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.perf_counter()\n",
    "elapsed = round(end_time - start_time, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b905892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª\n",
    "results = {\n",
    "    \"Precision@10\": round(np.mean(precisions), 4),\n",
    "    \"Recall\": round(np.mean(recalls), 4),\n",
    "    \"MAP\": round(np.mean(average_precisions), 4),\n",
    "    \"MRR\": round(np.mean(reciprocal_ranks), 4),\n",
    "    \"Execution Time (seconds)\": elapsed,\n",
    "    \"Queries Evaluated\": len(precisions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d779421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Execution Time (seconds)</th>\n",
       "      <th>Queries Evaluated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>811.79</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@10  Recall    MAP     MRR  Execution Time (seconds)  \\\n",
       "0        0.1168  0.8647  0.716  0.7555                    811.79   \n",
       "\n",
       "   Queries Evaluated  \n",
       "0               4999  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7897b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ JSON\n",
    "with open(\"bert_evaluation_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14fe8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
