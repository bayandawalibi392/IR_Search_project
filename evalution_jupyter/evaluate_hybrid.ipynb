{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1b609b",
   "metadata": {},
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from text_preprocessing_service import TextPreprocessingService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a7fc4",
   "metadata": {},
   "source": [
    "# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---\n",
    "SOURCE = \"quora\"  # Ø£Ùˆ \"quora\"\n",
    "MODELS_DIR = \"models\"\n",
    "INDEX_DIR = \"indexes\"\n",
    "TOP_N = 10\n",
    "ALPHA = 0.6  # ÙˆØ²Ù† TF-IDF Ù…Ù‚Ø§Ø¨Ù„ BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c28941",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e446f2",
   "metadata": {},
   "source": [
    "def embed_text(text):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    return output.last_hidden_state.mean(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad598a",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³\n",
    "inverted_index = joblib.load(os.path.join(INDEX_DIR, f\"inverted_index_{SOURCE}.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e283d",
   "metadata": {},
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª\n",
    "tfidf_vectorizer = joblib.load(os.path.join(MODELS_DIR, f\"tfidf_{SOURCE}_vectorizer.joblib\"))\n",
    "tfidf_doc_ids = joblib.load(os.path.join(MODELS_DIR, f\"tfidf_{SOURCE}_doc_ids.joblib\"))\n",
    "tfidf_matrix = joblib.load(os.path.join(MODELS_DIR, f\"tfidf_{SOURCE}_matrix.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035305f5",
   "metadata": {},
   "source": [
    "bert_doc_ids = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_doc_ids.joblib\"))\n",
    "bert_vectors = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_vectors.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9c1f5",
   "metadata": {},
   "source": [
    "tfidf_id_to_idx = {doc_id: i for i, doc_id in enumerate(tfidf_doc_ids)}\n",
    "bert_id_to_idx = {doc_id: i for i, doc_id in enumerate(bert_doc_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2faf2",
   "metadata": {},
   "source": [
    "# Ù…Ø¹Ø§Ù„Ø¬Ø©\n",
    "preprocessor = TextPreprocessingService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a911aeb",
   "metadata": {},
   "source": [
    "# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "conn = sqlite3.connect(\"ir_project.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7f290",
   "metadata": {},
   "source": [
    "cursor.execute(\"SELECT query_id, query_text FROM queries WHERE source = ?\", (SOURCE,))\n",
    "queries = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd5814",
   "metadata": {},
   "source": [
    "cursor.execute(\"SELECT query_id, doc_id FROM qrels WHERE source = ?\", (SOURCE,))\n",
    "qrels_raw = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31575d7b",
   "metadata": {},
   "source": [
    "# qrels ÙƒÙ‚Ø§Ù…ÙˆØ³\n",
    "qrels = {}\n",
    "for qid, doc_id in qrels_raw:\n",
    "    qrels.setdefault(qid, set()).add(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce8c1a",
   "metadata": {},
   "source": [
    "# --- ØªÙ‚ÙŠÙŠÙ… ---\n",
    "precisions, recalls, average_precisions, reciprocal_ranks = [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf5bca",
   "metadata": {},
   "source": [
    "print(f\"\\nâš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ {len(queries)} Ø§Ø³ØªØ¹Ù„Ø§Ù…...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e6499",
   "metadata": {},
   "source": [
    "for qid, query_text in tqdm(queries):\n",
    "    if qid not in qrels:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c8419",
   "metadata": {},
   "source": [
    "    relevant_docs = qrels[qid]\n",
    "    tokens = preprocessor.preprocess(query_text, return_as_string=False)\n",
    "    cleaned_query = preprocessor.preprocess(query_text, return_as_string=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6cf29",
   "metadata": {},
   "source": [
    "    # Ù…Ø±Ø´Ø­ÙˆÙ† Ù…Ù† Ø§Ù„ÙÙ‡Ø±Ø³\n",
    "    candidate_doc_ids = set()\n",
    "    for token in tokens:\n",
    "        if token in inverted_index:\n",
    "            candidate_doc_ids.update(inverted_index[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaeb62b",
   "metadata": {},
   "source": [
    "    common_doc_ids = list(candidate_doc_ids.intersection(tfidf_doc_ids).intersection(bert_doc_ids))\n",
    "    if not common_doc_ids:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bc284",
   "metadata": {},
   "source": [
    "    tfidf_indices = [tfidf_id_to_idx[doc_id] for doc_id in common_doc_ids]\n",
    "    bert_indices = [bert_id_to_idx[doc_id] for doc_id in common_doc_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec8d00",
   "metadata": {},
   "source": [
    "    # Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª\n",
    "    tfidf_query_vec = tfidf_vectorizer.transform([cleaned_query])\n",
    "    sims_tfidf = cosine_similarity(tfidf_query_vec, tfidf_matrix[tfidf_indices])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0cafd",
   "metadata": {},
   "source": [
    "    bert_query_vec = embed_text(cleaned_query)\n",
    "    sims_bert = cosine_similarity(bert_query_vec, bert_vectors[bert_indices])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b12680",
   "metadata": {},
   "source": [
    "    # Ø¯Ù…Ø¬ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª\n",
    "    final_sims = ALPHA * sims_tfidf + (1 - ALPHA) * sims_bert\n",
    "    ranked = [(doc_id, final_sims[i]) for i, doc_id in enumerate(common_doc_ids)]\n",
    "    ranked.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_docs = [doc_id for doc_id, _ in ranked[:TOP_N]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8866f6",
   "metadata": {},
   "source": [
    "    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\n",
    "    hits = [1 if doc in relevant_docs else 0 for doc in top_docs]\n",
    "    precisions.append(sum(hits) / TOP_N)\n",
    "    recalls.append(sum(hits) / len(relevant_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20f6d5",
   "metadata": {},
   "source": [
    "    # MAP\n",
    "    y_true = [1 if doc in relevant_docs else 0 for doc in common_doc_ids]\n",
    "    y_scores = final_sims\n",
    "    try:\n",
    "        ap = average_precision_score(y_true, y_scores)\n",
    "    except:\n",
    "        ap = 0.0\n",
    "    average_precisions.append(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446313c9",
   "metadata": {},
   "source": [
    "    # MRR\n",
    "    for rank, doc in enumerate(top_docs, 1):\n",
    "        if doc in relevant_docs:\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        reciprocal_ranks.append(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ae195",
   "metadata": {},
   "source": [
    "# --- Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---\n",
    "print(\"\\nğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù‡Ø¬ÙŠÙ† Ù…Ø¹ Ø§Ù„ÙÙ‡Ø±Ø³:\")\n",
    "print(f\"Precision@10: {np.mean(precisions):.4f}\")\n",
    "print(f\"Recall:        {np.mean(recalls):.4f}\")\n",
    "print(f\"MAP:           {np.mean(average_precisions):.4f}\")\n",
    "print(f\"MRR:           {np.mean(reciprocal_ranks):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06f28ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# conn.close()\n",
    "import os\n",
    "import sqlite3\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from text_preprocessing_service import TextPreprocessingService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7defe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---\n",
    "SOURCE = \"quora\"\n",
    "MODELS_DIR = \"models\"\n",
    "INDEX_DIR = \"indexes\"\n",
    "TOP_N = 10\n",
    "ALPHA = 0.6  # ÙˆØ²Ù† TF-IDF Ù…Ù‚Ø§Ø¨Ù„ BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb2c237",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd46ea9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    return output.last_hidden_state.mean(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df60bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
    "inverted_index = joblib.load(os.path.join(INDEX_DIR, f\"inverted_index_{SOURCE}.joblib\"))\n",
    "tfidf_vectorizer = joblib.load(os.path.join(MODELS_DIR, f\"tfidf_{SOURCE}_vectorizer.joblib\"))\n",
    "tfidf_doc_ids = joblib.load(os.path.join(MODELS_DIR, f\"tfidf_{SOURCE}_doc_ids.joblib\"))\n",
    "tfidf_matrix = joblib.load(os.path.join(MODELS_DIR, f\"tfidf_{SOURCE}_matrix.joblib\"))\n",
    "bert_doc_ids = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_doc_ids.joblib\"))\n",
    "bert_vectors = joblib.load(os.path.join(MODELS_DIR, f\"bert_{SOURCE}_vectors.joblib\"))\n",
    "tfidf_id_to_idx = {doc_id: i for i, doc_id in enumerate(tfidf_doc_ids)}\n",
    "bert_id_to_idx = {doc_id: i for i, doc_id in enumerate(bert_doc_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bcb7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ù…Ø¹Ø§Ù„Ø¬Ø©\n",
    "preprocessor = TextPreprocessingService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf23ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "conn = sqlite3.connect(\"ir_project.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT query_id, query_text FROM queries WHERE source = ?\", (SOURCE,))\n",
    "queries = cursor.fetchall()\n",
    "cursor.execute(\"SELECT query_id, doc_id FROM qrels WHERE source = ?\", (SOURCE,))\n",
    "qrels_raw = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58742da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qrels ÙƒÙ‚Ø§Ù…ÙˆØ³\n",
    "qrels = {}\n",
    "for qid, doc_id in qrels_raw:\n",
    "    qrels.setdefault(qid, set()).add(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb80945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ØªÙ‚ÙŠÙŠÙ… ---\n",
    "precisions, recalls, average_precisions, reciprocal_ranks = [], [], [], []\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e2ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ 5000 Ø§Ø³ØªØ¹Ù„Ø§Ù…...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nâš™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ {len(queries)} Ø§Ø³ØªØ¹Ù„Ø§Ù…...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b886b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4732/5000 [11:57<00:34,  7.85it/s]C:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [12:43<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for qid, query_text in tqdm(queries):\n",
    "    if qid not in qrels:\n",
    "        continue\n",
    "\n",
    "    relevant_docs = qrels[qid]\n",
    "    tokens = preprocessor.preprocess(query_text, return_as_string=False)\n",
    "    cleaned_query = preprocessor.preprocess(query_text, return_as_string=True)\n",
    "\n",
    "    candidate_doc_ids = set()\n",
    "    for token in tokens:\n",
    "        if token in inverted_index:\n",
    "            candidate_doc_ids.update(inverted_index[token])\n",
    "\n",
    "    common_doc_ids = list(candidate_doc_ids.intersection(tfidf_doc_ids).intersection(bert_doc_ids))\n",
    "    if not common_doc_ids:\n",
    "        continue\n",
    "\n",
    "    tfidf_indices = [tfidf_id_to_idx[doc_id] for doc_id in common_doc_ids]\n",
    "    bert_indices = [bert_id_to_idx[doc_id] for doc_id in common_doc_ids]\n",
    "\n",
    "    tfidf_query_vec = tfidf_vectorizer.transform([cleaned_query])\n",
    "    sims_tfidf = cosine_similarity(tfidf_query_vec, tfidf_matrix[tfidf_indices])[0]\n",
    "\n",
    "    bert_query_vec = embed_text(cleaned_query)\n",
    "    sims_bert = cosine_similarity(bert_query_vec, bert_vectors[bert_indices])[0]\n",
    "\n",
    "    final_sims = ALPHA * sims_tfidf + (1 - ALPHA) * sims_bert\n",
    "    ranked = [(doc_id, final_sims[i]) for i, doc_id in enumerate(common_doc_ids)]\n",
    "    ranked.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_docs = [doc_id for doc_id, _ in ranked[:TOP_N]]\n",
    "\n",
    "    hits = [1 if doc in relevant_docs else 0 for doc in top_docs]\n",
    "    precisions.append(sum(hits) / TOP_N)\n",
    "    recalls.append(sum(hits) / len(relevant_docs))\n",
    "\n",
    "    y_true = [1 if doc in relevant_docs else 0 for doc in common_doc_ids]\n",
    "    y_scores = final_sims\n",
    "    try:\n",
    "        ap = average_precision_score(y_true, y_scores)\n",
    "    except:\n",
    "        ap = 0.0\n",
    "    average_precisions.append(ap)\n",
    "\n",
    "    for rank, doc in enumerate(top_docs, 1):\n",
    "        if doc in relevant_docs:\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "            break\n",
    "    else:\n",
    "        reciprocal_ranks.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf0808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.perf_counter()\n",
    "elapsed_time = round(end_time - start_time, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe72799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---\n",
    "results = {\n",
    "    \"Precision@10\": round(np.mean(precisions), 4),\n",
    "    \"Recall\": round(np.mean(recalls), 4),\n",
    "    \"MAP\": round(np.mean(average_precisions), 4),\n",
    "    \"MRR\": round(np.mean(reciprocal_ranks), 4),\n",
    "    \"Execution Time (seconds)\": elapsed_time,\n",
    "    \"Queries Evaluated\": len(precisions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f75479bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Execution Time (seconds)</th>\n",
       "      <th>Queries Evaluated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1188</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>763.42</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@10  Recall     MAP     MRR  Execution Time (seconds)  \\\n",
       "0        0.1188  0.8793  0.7314  0.7699                    763.42   \n",
       "\n",
       "   Queries Evaluated  \n",
       "0               4999  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed7a2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "with open(\"hybrid_evaluation_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00eb3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
